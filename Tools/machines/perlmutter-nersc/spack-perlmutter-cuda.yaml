# This is a Spack environment file.
#
# This environment can be used to install all dependencies to build the manual
# locally.
#
# Activating and installing this environment will provide all dependencies
# that are needed for full-feature development.
#   https://spack.readthedocs.io/en/latest/environments.html
#
# Inside the directory of this file
#   spack env create -d /global/common/software/${proj%_g}/$USER/spack-envs/warpx-perlmutter-cuda spack-perlmutter-cuda.yaml
#   spack env activate /global/common/software/${proj%_g}/$USER/spack-envs/warpx-perlmutter-cuda
#   spack install  # only needed the first time
#
spack:
  # the top part is using the official template to chain the E4S modules at NERSC
  #   https://docs.nersc.gov/applications/e4s/spack_environments/
  #   https://github.com/NERSC/spack-infrastructure/blob/main/spack-configs/perlmutter-user-spack/spack.yaml
  config:
    concretization: together
    build_stage: $env/var/spack/stage
    misc_cache: $env/var/spack/misc_cache
    concretizer: clingo
    install_tree: $env/opt/spack

  # Perlmutter compiler and package preferences
  include:
  - /global/common/software/spackecp/perlmutter/spack_settings/compilers.yaml
  - /global/common/software/spackecp/perlmutter/spack_settings/packages.yaml

  mirrors:
    perlmutter-spack-develop: file:///global/common/software/spackecp/mirrors/perlmutter-spack-develop
    perlmutter-e4s-22.05: file:///global/common/software/spackecp/mirrors/perlmutter-e4s-22.05

  # Spack Chaining, if you want to use existing software stack
  upstreams:
    perlmutter-e4s-22.05:
      install_tree: /global/common/software/spackecp/perlmutter/e4s-22.05/default/spack/opt/spack

  # these are the WarpX dependencies
  specs:
  # https://github.com/ornladios/ADIOS2/issues/3332
  - adios2 ~cuda
  - blaspp
  - boost
  - ccache
  - cmake
  - cuda
  - hdf5
  - lapackpp
  - mpi
  - pkgconfig
  - python
  - py-cython
  - py-mpi4py
  - py-numpy
  - py-pip
  - py-setuptools
  - py-wheel
# Ascent does not build as of 22.05 (cannot find MPI)
#  - ascent +adios2 +python ~fortran ~shared
#  - conduit ~fortran
#  - vtk-m ~shared
# saving time
#  - sensei +ascent ~catalyst +python
# CUDA Python dev
#  - py-cupy
#  - py-numba
# This always enables DevilRay, which builds too long on CUDA and we mainly use VTK-m
#  - ecp-data-vis-sdk +adios2 +ascent +hdf5 +sensei
# skipped to save time: 3D post-processing
#  - paraview +adios2 +python3 +qt
# skipped to save time, because they are faster installed via pip afterwards
#  python3 -m pip install h5py libensemble matplotlib nlopt openpmd-api openpmd-viewer pandas pytest scipy yt
#  - nlopt
#  - openpmd-api +python
#  - py-h5py
#  - py-libensemble +nlopt
#  - py-matplotlib +animation +fonts +latex +movies
#  - py-openpmd-viewer +numba +jupyter
#  - py-pandas
#  - py-pytest
#  - py-pyqt5
#  - py-scipy
#  - py-yt

  packages:
    all:
      # note: add +cuda cuda_arch=80
      #       or respective CUDA capability instead of 80 to variants below
      variants:: +mpi ~fortran +cuda cuda_arch=80
